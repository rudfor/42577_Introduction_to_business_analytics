{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Notebook 2 - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that simulates a model $y=\\beta_0+\\beta_1*x+\\epsilon \\text{   } $. We give you the first line (signature):\n",
    "\n",
    ">def generate_simple_model(X, beta0, beta1, sigma):\n",
    "\n",
    "where X is a vector with x values, beta0 and beta1 are the parameters, and sigma is the standard deviation of the error term. The function should return the modelled values of $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will allow you to create data to play with, below. \n",
    "\n",
    "Let's just test it, with a model that is $y=-1+3*x+N(0,\\sigma^2)\\text{   }$ (i.e. standard deviation is $\\sigma$, variance is $\\sigma^2$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, with NO error ($\\sigma=0$)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xe=np.arange(24)    \n",
    "ye=generate_simple_model(Xe, -1, 3, 0)#[-1+3*x for x in Xe] # NOTE: This is the function that you generated above\n",
    "print(len(Xe))\n",
    "\n",
    "plt.scatter(Xe, ye)\n",
    "plt.annotate('$y=-1+3x$', xy=(0, 60), xytext=(0, 60), fontsize=20)\n",
    "plt.plot([0,24], [-1, 71], color=\"red\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with a little bit of error ($\\sigma=9$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma=9\n",
    "ye=generate_simple_model(Xe, -1, 3, sigma)\n",
    "\n",
    "plt.scatter(Xe, ye)\n",
    "plt.annotate('$y=-1+3x+N(0,9^2)$', xy=(0, 60), xytext=(0, 60), fontsize=20)\n",
    "plt.plot([0,24], [-1, 71], color=\"red\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just ONE sample (i.e. one possible dataset) that could be generated by our simple model. It is important to see that each model actually implies a full distribution of data.\n",
    "\n",
    "To make this point more clear, let's generate a very large number (e.g. 500) of samples and plot them at the same time.\n",
    "\n",
    "We generate them, you plot them, ok? ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xe=np.arange(0, 24, 0.01)    \n",
    "N_fun=500  #number of samples to generate\n",
    "ys=[]\n",
    "for i in range(N_fun):\n",
    "    ys.append(generate_simple_model(Xe, -1, 3, 9))\n",
    "\n",
    "Y=np.matrix(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the array Xe and matrix Y. They contain all the data. You can all check the sizes. Note also that ys is a list of numpy arrays whereas Y is numpy matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you now plot/visualize all the data in ys using a scatter plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this mean? \n",
    "\n",
    "An interesting way to look is to do like a \"vertical cut\" of the graph (like a cross-section, or transversal cut). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a histogram of the data at x=10 and at x=20. Can you see them in the figure above? (HINT: Here, it may be easier to use the matrix Y that we created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that implements the linear regression estimator, based on the slides (Least Squares estimator). \n",
    "\n",
    "It should look like:\n",
    "\n",
    ">def my_lin_reg(x, y):\n",
    ">\n",
    ">      \\# put your code here... ;-)\n",
    ">\n",
    ">      return beta0, beta1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use a small dataset, just to try your solution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(10)\n",
    "y=generate_simple_model(x, -1, 3, 9)\n",
    "beta0, beta1=my_lin_reg(x,y)\n",
    "print(\"my linear regression: \\n beta0=%f, beta1=%f\"%(beta0, beta1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now you were able to estimate the parameters of the linear regression (the values of betas). The only missing part is how to predict. In  other words, given a new input, x, what is the respective (predicted) y?\n",
    "\n",
    "Can you write the function? It should look like:\n",
    "\n",
    "> def predict(x, beta0, beta1):\n",
    ">        \\# ... put your code here ;-)\n",
    ">\n",
    ">        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats, you have built your own first Machine Learning Regression algorithm!\n",
    "\n",
    "...sadly, you didn't have to. You could have used sklearn!... \n",
    "\n",
    "**sklearn is a VERY popular Python module in Data Sciences. Make sure you have it installed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how it would look like, with sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr=linear_model.LinearRegression(fit_intercept=False)\n",
    "x_= np.c_[np.ones(len(x)),np.array(x)]\n",
    "regr.fit(x_, y)\n",
    "print(\"sklearn linear regression:\", regr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should find almost no difference..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same for predictions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict(x, beta0, beta1))\n",
    "print(regr.predict(x_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously equal..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should also notice that there can be quite some substantial error in the beta estimates (compare the results you get with the \"true\" model...).\n",
    "\n",
    "Notice that you have a very small dataset (10 points). The question arises: does the error become smaller with larger datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trueBeta0=-1\n",
    "trueBeta1=3\n",
    "trueSigma=9\n",
    "N=np.arange(3, 1000)\n",
    "diff0=[]\n",
    "diff1=[]\n",
    "for n in N:\n",
    "    x=np.arange(n)\n",
    "    y=generate_simple_model(x, trueBeta0, trueBeta1, trueSigma)\n",
    "    beta0, beta1=my_lin_reg(x,y)\n",
    "    diff0.append(abs(trueBeta0-beta0))\n",
    "    diff1.append(abs(trueBeta1-beta1))\n",
    "    \n",
    "plt.figure(num=None, figsize=(40, 20), facecolor='w', edgecolor='k')\n",
    "plt.plot(N, diff0, label=\"Error in beta0\")\n",
    "plt.plot(N, diff1, label=\"Error in beta1\")\n",
    "plt.legend(prop={'size':60})\n",
    "plt.rc('xtick', labelsize=30)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=30)    # fontsize of the tick labels\n",
    "plt.xlabel(\"N (dataset size)\", size=30)\n",
    "plt.ylabel(\"Error\", size=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, isn't it? Notice that the intercept converges much slower than the coefficient of x. For more information on why this happens see the equations for the standard error in the parameter estimates (Equation 3.8 on page 75 of the Intro to Statistical Learning textbook). \n",
    "\n",
    "Let's now check how the model is able to approximate sigma (the standard deviation of the error term) as the number of data points grow. Note that an unbiased estimate of sigma from our training data is given by: $\\hat{\\sigma}^2=\\frac{e^T e}{n-2}$, where $e$ is the vector of residuals (we won't get into the technical details of this). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interruption 23 (OLS)\n",
    "\n",
    "trueSigma=9\n",
    "N=np.arange(3, 1000)\n",
    "sigma=[]\n",
    "for n in N:\n",
    "    x=np.arange(n)\n",
    "    y=generate_simple_model(x, trueBeta0, trueBeta1, trueSigma)\n",
    "    beta0, beta1=my_lin_reg(x,y)\n",
    "    predictions=np.array([predict(xj, beta0, beta1) for xj in x])\n",
    "    sigma.append(trueSigma-np.sqrt(np.dot(predictions-np.array(y), predictions-np.array(y))/(n-2)))\n",
    "    \n",
    "plt.figure(num=None, figsize=(40, 20), facecolor='w', edgecolor='k')\n",
    "plt.plot(N, sigma, label=\"Error in sigma ($\\sigma^{true}-\\sigma^{estimated}$)\")\n",
    "plt.legend(prop={'size':60})\n",
    "plt.xticks(size=30)\n",
    "plt.yticks(size=30)\n",
    "plt.xlabel(\"N (dataset size)\", size=30)\n",
    "plt.ylabel(\"Error\", size=30)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to converge a bit...\n",
    "\n",
    "Another way to look at this is to see the distribution (histogram) of sigma as more data is available. Can you plot that graph?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go a bit more crazy, and add much more datapoints... \n",
    "\n",
    "**IMPORTANT: this may take a long time, may too long, depending on your computer. That's why we leave a pre-generated picture in the notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interruption 23 (OLS)\n",
    "\n",
    "trueBeta0=-1\n",
    "trueBeta1=3\n",
    "trueSigma=9\n",
    "N=np.arange(1000, 500000, 1000)\n",
    "diff0=[]\n",
    "diff1=[]\n",
    "for n in N:\n",
    "    x=np.arange(n)\n",
    "    y=generate_simple_model(x, trueBeta0, trueBeta1, trueSigma)\n",
    "    beta0, beta1=my_lin_reg(x,y)\n",
    "    diff0.append(abs(trueBeta0-beta0))\n",
    "    diff1.append(abs(trueBeta1-beta1))\n",
    "\n",
    "plt.figure(num=None, figsize=(40, 20), facecolor='w', edgecolor='k')\n",
    "plt.plot(N, diff0, label=\"Error in beta0\")\n",
    "plt.plot(N, diff1, label=\"Error in beta1\")\n",
    "plt.legend(prop={'size':60})\n",
    "plt.xticks(size=30)\n",
    "plt.yticks(size=30)\n",
    "plt.xlabel(\"N (dataset size)\", size=30)\n",
    "plt.ylabel(\"Error\", size=30)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to converge all right (NOTICE the y axis scale, and compare with the previous one!). In fact, the error for beta1 is practically zero since very early, while beta0 tends to have a small error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use the NYC dataset, having x=hour, as in the slides..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to run the least squares algorithm on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=pd.read_csv(\"pickups_zone_1_15min.csv\")\n",
    "#Same code as above, just for reference (and to initialize the variables, just in case...)\n",
    "\n",
    "x= np.c_[np.ones(len(f)),f['hour']]\n",
    "y= np.array(f['pickups'], ndmin=2).T\n",
    "\n",
    "regr=linear_model.LinearRegression(fit_intercept=False)\n",
    "regr.fit(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the slides, can you compute the mean absolute error and the root mean squared error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a scatter of pickups vs hour, and the fitted line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check: are the OLS conditions verified?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now do not know the true distribution. We only have the data. \n",
    "\n",
    "For the expected value of epsilon, $E(\\epsilon_j)$, we will average from the sample. We have done this exact same thing before, remember?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error=regr.predict(x) - y\n",
    "print(\"Expected value of the error (or Average error, AE): %.2f\" % np.mean(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the variance of the error term, we can apply the formula from earlier, $\\hat{\\sigma}^2=\\frac{e^T e}{n-2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make things easier we will convert the 2-D error array to a 1-D array\n",
    "error = (regr.predict(x) - y).flatten()\n",
    "print(\"variance of all data is:\", np.dot(error,error)/(len(y)-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... There's nothing wrong with these numbers, is there? Well, of course the AE would be 0 for all data! And the variance is one single value (9966.72...), so of course it's... constant!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, kind of... We can make some basic checks to see more.\n",
    "\n",
    "For example, we can split the dataset into two chunks, and check if the variance is the same... An idea: divide data into before noon and after noon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmorning=f.loc[f['hour'] <= 12]\n",
    "fafternoon=f.loc[f['hour'] > 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's now compare the means and variances in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_morning=np.c_[np.ones(len(fmorning)),fmorning['hour']]\n",
    "y_morning=np.array(fmorning['pickups'], ndmin=2).T\n",
    "error_morning=(regr.predict(x_morning) - y_morning).flatten()\n",
    "\n",
    "print(\"mean of error on morning data is:\", np.mean(error_morning))\n",
    "print(\"variance of error on morning data is:\", np.dot(error_morning,error_morning)/(len(error_morning)-2))\n",
    "\n",
    "x_afternoon=np.c_[np.ones(len(fafternoon)),fafternoon['hour']]\n",
    "y_afternoon=np.array(fafternoon['pickups'], ndmin=2).T\n",
    "error_afternoon=(regr.predict(x_afternoon) - y_afternoon).flatten()\n",
    "\n",
    "print(\"mean of error on afternoon data is:\", np.mean(error_afternoon))\n",
    "print(\"variance of error on afternoon data is:\", np.dot(error_afternoon,error_afternoon)/(len(error_afternoon)-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so... a little different, uh? Since the two datasets are extremely large, we can assume that indeed the true variance is not constant. The picture below gives an intuition of what's happening\n",
    "\n",
    "![alt text](mean_variance_diagram.png \"Mean Variance intuition\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset is so different in those two parts of the day, a solution would be to create two separate models (one for morning, another for the afternoon). But, for the sake of not distracting ourselves, let's keep with a single one for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's play with more variables in our model, starting with hour and minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.c_[np.ones(len(f)),f['hour'], f['minute']]\n",
    "y= np.array(f['pickups'], ndmin=2).T\n",
    "\n",
    "regr=linear_model.LinearRegression(fit_intercept=False)\n",
    "regr.fit(x, y);\n",
    "print(regr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now very difficult to visualize, with two x variables!\n",
    "\n",
    "So, we will now use a 45 degree plot (predicted pickups VS observed pickups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y, regr.predict(x))\n",
    "plt.ylabel(\"predicted\")\n",
    "plt.xlabel(\"observed\")\n",
    "plt.plot([0, 400], [0, 400], color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... it looks TERRIBLE!... What are the error statistics now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute error (MAE): %.2f\"% np.mean(abs(regr.predict(x) - y)))\n",
    "# The mean squared error\n",
    "print(\"Root Mean squared error: %.2f\"\n",
    "      % np.sqrt(np.mean((regr.predict(x) - y) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, it did NOT improve AT ALL!!!!  :-(  \n",
    "\n",
    "Let's take a look at the correlations, to understand why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.iloc[:,1:].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we added the pickup lags instead?\n",
    "\n",
    "Here the lag function we used last week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildLaggedFeatures(s,columns, lag=2,dropna=True):\n",
    "    '''\n",
    "    From http://stackoverflow.com/questions/20410312/how-to-create-a-lagged-data-structure-using-pandas-dataframe\n",
    "    Builds a new DataFrame to facilitate regressing over all possible lagged features\n",
    "    '''\n",
    "    if type(s) is pd.DataFrame:\n",
    "        new_dict={}\n",
    "        for c in s.columns:\n",
    "            new_dict[c]=s[c]\n",
    "        for col_name in columns:\n",
    "            new_dict[col_name]=s[col_name]\n",
    "            # create lagged Series\n",
    "            for l in range(1,lag+1):\n",
    "                new_dict['%s_lag%d' %(col_name,l)]=s[col_name].shift(l)\n",
    "        res=pd.DataFrame(new_dict,index=s.index)\n",
    "\n",
    "    elif type(s) is pd.Series:\n",
    "        the_range=range(lag+1)\n",
    "        res=pd.concat([s.shift(i) for i in the_range],axis=1)\n",
    "        res.columns=['lag_%d' %i for i in the_range]\n",
    "    else:\n",
    "        print('Only works for DataFrame or Series')\n",
    "        return None\n",
    "    if dropna:\n",
    "        return res.dropna()\n",
    "    else:\n",
    "        return res "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also create a function to make our 45 degree linear regression plots and provide some statistics at one go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def my_plot(regr, x, y, size=0.1):\n",
    "\n",
    "    # The coefficients\n",
    "    print('Coefficients: \\n', regr.coef_)\n",
    "    # The mean absolute error    \n",
    "    print(\"Mean Absolute error (MAE): %.2f\"% np.mean(abs(regr.predict(x) - y)))\n",
    "    # The mean squared error\n",
    "    print(\"Root Mean squared error: %.2f\"\n",
    "          % np.sqrt(np.mean((regr.predict(x) - y) ** 2)))\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print('Variance score: %.2f' % regr.score(x, y))\n",
    "          \n",
    "    # Plot outputs\n",
    "    plt.scatter(y, regr.predict(x), color='blue',linewidth=3)\n",
    "    plt.plot([0, 800], [0, 800], color=\"red\")\n",
    "    plt.rc('xtick', labelsize=10)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=10)    # fontsize of the tick labels\n",
    "    plt.xlabel(\"observed\")\n",
    "    plt.ylabel(\"predicted\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_lagged=buildLaggedFeatures(f, ['pickups'], lag=2)\n",
    "fllen=len(f_lagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_lagged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we have a more complete model now... what about the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.c_[np.ones(len(f_lagged)),f_lagged['pickups_lag1'], f_lagged['pickups_lag2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y=np.array(f_lagged['pickups'], ndmin=2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr=linear_model.LinearRegression(fit_intercept=False)\n",
    "regr.fit(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_plot(regr, x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, waaaay better!... :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Now, it's your turn! Can you improve this model further?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
