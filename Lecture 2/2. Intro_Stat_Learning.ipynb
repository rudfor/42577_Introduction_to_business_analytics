{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Notebook 1 - Introduction to Statistical Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the required imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "plt.style.use('ggplot')\n",
    "np.random.seed(seed=0)\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that generates data from our 'true' model $y=\\beta_0+\\beta_1x  +\\beta_2x^2 + \\beta_3x^3 +\\epsilon \\text{   } $. We assume the error term is a normal (Gaussian) distribution with variance $\\sigma^2$. We give you the function signature:\n",
    "\n",
    ">def generate_true_model(X, beta0, beta1,  beta2, beta3, sigma):\n",
    "\n",
    "where X is a vector with values of the feature or variable x, beta0, beta1, beta2 and beta3 are the model parameters, and sigma is the standard deviation of the error term. \n",
    "\n",
    "NOTE: In reality, we will never know this 'true model' $f(x)$\n",
    "\n",
    "HINT: To sample values from a normal distribution, you can use the np.random.normal() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will allow you to create data to play with, below. \n",
    "\n",
    "Let's just test it, with a model that is $y=20-1.5x+0.5x^2-0.02x^3+N(0,\\sigma^2)\\text{   }$ (i.e. standard deviation is $\\sigma$, variance is $\\sigma^2$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, with NO error ($\\sigma=0$)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xe=np.arange(0,25,0.25)    \n",
    "ye=generate_true_model(Xe, 20,-1.5,0.5,-0.02, 0) \n",
    "plt.scatter(Xe, ye,alpha=0.5)\n",
    "plt.annotate('$y=20-1.5x+0.5x^2-0.02x^3$', xy=(0, 10), xytext=(0, 10), fontsize=10)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we add a little bit of noise or error ($\\sigma=6$). This error could be due to several factors, for example the response variable y depends on features other than x, or there is an error associated with the measurement of y ,etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xe=np.arange(0,25,0.25)    \n",
    "ye=generate_true_model(Xe, 20,-1.5,0.5,-0.02, 6) \n",
    "plt.scatter(Xe, ye,alpha=0.5)\n",
    "plt.annotate('$y=20-1.5x+0.5x^2-0.02x^3 + N(0,6)$', xy=(0, 0), xytext=(0, 0), fontsize=10)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a simple linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we will train a simple linear regression model (we will get into more details of this model in the next part of the lecture); in this session and in for the rest of the course, we will often use the sklearn library (https://scikit-learn.org/stable/). We will call this model 'M1'.\n",
    "\n",
    "#### The linear model takes the following form: $y =  \\beta_0+\\beta_1x  + \\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the linear regression model from sklearn\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we define the model object\n",
    "M1 = linear_model.LinearRegression()\n",
    "Xe = Xe.reshape(-1,1)  # Convert from a 1D to a 2D numpy array for SK learn\n",
    "\n",
    "# Fit the model using the data in Xe and ye\n",
    "M1.fit(Xe,ye)\n",
    "# Display model coefficients\n",
    "print(M1.coef_,M1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_M1_predict_train = M1.predict(Xe) # model predictions on training set\n",
    "plt.plot(Xe, Y_M1_predict_train)\n",
    "plt.scatter(Xe, ye,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the MSE on the train set\n",
    "MSE_train_M1 = np.dot((ye-Y_M1_predict_train),(ye-Y_M1_predict_train))/(len(ye))\n",
    "print('MSE M1 Train',MSE_train_M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a test set and compute MSE on test set\n",
    "\n",
    "# First we generate a large random set of test points\n",
    "Xe_test = np.random.uniform(0,25,5000)\n",
    "\n",
    "# Compute the response variable for these tests points using our function\n",
    "ye_test = generate_true_model(Xe_test, 20,-1.5,0.5,-0.02, 6) \n",
    "Xe_test = Xe_test.reshape(-1,1)\n",
    "\n",
    "# Generate the model predictions for test set\n",
    "Y_M1_predict_test = M1.predict(Xe_test) \n",
    "\n",
    "# Compute the MSE on the test set\n",
    "MSE_test_M1 = np.dot((ye_test-Y_M1_predict_test),(ye_test-Y_M1_predict_test))/len(ye_test)\n",
    "print('MSE M1 Test',MSE_test_M1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a fourth order polynomial model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we will train a fourth-degree polynomial regression model, which takes the form: \n",
    "#### $y =  \\beta_0+ \\sum_{j=1}^{j=4} \\beta_j x^j  + \\epsilon$\n",
    "#### We will call this model 'M2'. Observe that this is a more complex (more flexibility) model than the linear model and has 5 parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# To fit this polynomial regression we will first use a feature of sklearn to create polynomial features \n",
    "# from a given variable X. In this case X^2, X^3, X^4.\n",
    "\n",
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly_features = poly.fit_transform(Xe.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(poly_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then fit a standard linear model with the polynomial features\n",
    "\n",
    "M2 = linear_model.LinearRegression()\n",
    "M2.fit(poly_features, ye)\n",
    "print(M2.coef_,M2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_M2_predict_train = M2.predict(poly_features) # model predictions on training set\n",
    "plt.plot(Xe, Y_M2_predict_train)\n",
    "plt.scatter(Xe, ye,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the MSE on the train set\n",
    "MSE_train_M2 = np.dot((ye-Y_M2_predict_train),(ye-Y_M2_predict_train))/(len(ye))\n",
    "print('MSE M2 Train',MSE_train_M2)\n",
    "# Compute the MSE on the test set\n",
    "poly_test = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly_features_test = poly_test.fit_transform(Xe_test.reshape(-1, 1))\n",
    "Y_M2_predict_test = M2.predict(poly_features_test)\n",
    "MSE_test_M2 = np.dot((ye_test-Y_M2_predict_test),(ye_test-Y_M2_predict_test))/len(ye_test)\n",
    "print('MSE M2 Test',MSE_test_M2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a 10th order polynomial model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally we will train a tenth-degree polynomial regression model, which takes the form: \n",
    "#### $y =  \\beta_0+ \\sum_{j=1}^{j=10} \\beta_j x^j  + \\epsilon$\n",
    "#### We will call this model 'M3'. Observe that this is the most complex model and has 11 parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_10 = PolynomialFeatures(degree=10, include_bias=False)\n",
    "poly_features_10 = poly_10.fit_transform(Xe.reshape(-1, 1))\n",
    "M3 = linear_model.LinearRegression()\n",
    "M3.fit(poly_features_10, ye)\n",
    "print(M3.coef_,M3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_M3_predict_train = M3.predict(poly_features_10) # model predictions on training set\n",
    "plt.plot(Xe, Y_M3_predict_train)\n",
    "plt.scatter(Xe, ye,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the MSE on the train set\n",
    "MSE_train_M3 = np.dot((ye-Y_M3_predict_train),(ye-Y_M3_predict_train))/(len(ye))\n",
    "print('MSE M3 Train',MSE_train_M3)\n",
    "# Compute the MSE on the test set\n",
    "poly_10_test = PolynomialFeatures(degree=10, include_bias=False)\n",
    "poly_features_10_test = poly_10_test.fit_transform(Xe_test.reshape(-1, 1))\n",
    "Y_M3_predict_test = M3.predict(poly_features_10_test)\n",
    "MSE_test_M3 = np.dot((ye_test-Y_M3_predict_test),(ye_test-Y_M3_predict_test))/len(ye_test)\n",
    "print('MSE M3 Test',MSE_test_M3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a table summarizing the training and test MSE for the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_Models = [[\"M1 (Linear)\", MSE_train_M1, MSE_test_M1], \n",
    "        [\"M2 (poly - 4)\", MSE_train_M2, MSE_test_M2], \n",
    "        [\"M3 (poly - 10)\", MSE_train_M3, MSE_test_M3]]\n",
    "col_names = [\"Model\", \"MSE Train\", \"MSE Test\"]\n",
    "print(tabulate(MSE_Models, headers=col_names, tablefmt=\"grid\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
