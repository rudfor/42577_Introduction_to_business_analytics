{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Business Analytics\n",
    "\n",
    "## Lecture 1 - Numpy, statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome back! :-) \n",
    "\n",
    "Today, we'll explore in more depth the possibilities providaded by the Python Numpy module. We lined up an incremental set of exercises that will end up with your first descriptive statistics analysis of real data!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's start. Since we are going to work with numpy, let's just import it, shall we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need some data. Please open the file \"pickups_zone_1_15min.csv\". This corresponds to the series of taxi-pickups in New York zone 1 (an area in the Manhattan island). \n",
    "\n",
    "You can use the function open(file), which **returns** a file stream. So, when we write f=open(\"your filename here\"), the object f becomes a \"file stream\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, so we have the file stream, now we need to get to its content. This stream has a method to read all the lines at once (method readlines()). Let's use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to be sure, let's check how many lines the file actually has (it should be 262849, if it's different, there's something wrong...). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first 10 lines of this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, so you have temporal attributes, and the actual number of pickps.\n",
    "\n",
    "So, print **only** the pickups part. \n",
    "\n",
    "A tip - look what the following code does:\n",
    "\n",
    "> x=\"1,2,3,4\"\n",
    "\n",
    ">xsplitted=x.split(',')\n",
    "\n",
    "\n",
    ">print(xsplitted)\n",
    "\n",
    ">print(xsplitted[2])\n",
    "\n",
    "Output:\n",
    "\n",
    "['1', '2', '3', '4']\n",
    "\n",
    "3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, our goal is thus to make a **single** list with all the pickup data. You need to go over each line, get the pickup value, convert it to an integer, and add it to this list. \n",
    "\n",
    "Can you do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, so now you have an actual time series dataset. As you'll shortly see, it's very useful to have the respective time stamps (not just know that it is a sequence of values, also know exactly **when** each value occured)\n",
    "\n",
    "Notice, however, that the values for the date are split into 3 fields. More importantly, for Python, they are just numbers that have nothing to do with time. Luckily, there's class called datetime.datetime (the repetition here is intentional...). \n",
    "\n",
    "Here's some example code for you:\n",
    ">from datetime import datetime as dt\n",
    "\n",
    ">s=\"2017-09-11\"\n",
    ">\n",
    ">print(type(s))\n",
    ">\n",
    ">time=dt.strptime(s,  '%Y-%m-%d')\n",
    ">\n",
    ">print(type(time))\n",
    ">\n",
    ">print(time)\n",
    ">\n",
    ">time=time.replace(hour=14, minute=35)\n",
    ">\n",
    ">print(time)\n",
    "\n",
    "\n",
    "Output:\n",
    "\n",
    "\n",
    "<class 'str' &gt;\n",
    "\n",
    "<class 'datetime.datetime' &gt;\n",
    "\n",
    "2017-09-11 00:00:00\n",
    "\n",
    "2017-09-11 14:35:00\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "So, it creates a \"datetime\" object, that has everything you need to know about the time of that data point. It's pretty handy as you'll see later. \n",
    "\n",
    "Like what you did in the previous exercise, we now want a single list with all the datetime objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to reorganize your code a bit. You've made a few things above:\n",
    "- load a file\n",
    "- go over the content of the file to create a list with pickup data\n",
    "- go over the content of the file to create a list of datetime objects\n",
    "\n",
    "Let's put them together in a function that reads a file (with name fscv) and returns the two lists mentioned. I'll give you the first and last lines:\n",
    "\n",
    ">def read_csv(fcsv):\n",
    ">\n",
    ">      ...  #you just need to fill this part! ;-)\n",
    ">\n",
    ">      return pickups, times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with this function, you can run all the above with different files with a single command! Do you want to try?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create two numpy arrays from our two lists \n",
    "\n",
    "**note:** you can create a numpy array with the command numpy.array(_your_data_here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pickup vector can be used right away to make a histogram. Think about it: what should the distribution of number of pickups (i.e. the observable taxi demand) look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   # we add this for you... \n",
    "#Yes, without this line below you'll run into trounble (wanna try?   ;-) )\n",
    "%matplotlib inline       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the function .hist(...). is a histogram plot function in matplolib. Do you want to try it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hhmmm... was this what you were expecting?... \n",
    "\n",
    "Another interesting way to look at this data is simply by plotting directly with a scatter plot, where the x axis is the index of the datapoint, and the y axis is the total number of pickups.\n",
    "\n",
    "Tip: to see better the data try playing with the size of the dots (for example, put s=0.1 as an argument to the scatter call) and the transparency of the graph plot (using the alpha attribute). By default, alpha=1. If you would like to form the graph plot more transparent, you can make alpha less than 1, such as 0.5 or 0.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sort of pattern is intriguing. There seems to be two general \"trends\" of taxi pickups in this area. Do you think it relates with time of day? It would make some sense (e.g. during the night, low values, during peak hours, high values). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to check this, but a simple one is to make a small change in the temporal vector. Instead of each element of this vector corresponding to absolute time (the *actual* date and time), why not just represent the minutes since midnight? \n",
    "\n",
    "Can you make a new vector with that content?\n",
    "\n",
    "**Tip on how to get the hour and minute**:\n",
    ">from datetime import datetime as dt\n",
    ">\n",
    ">s=\"2017-09-11 18:35:11\"\n",
    ">\n",
    ">d=dt.strptime(s, \"%Y-%m-%d %H:%M:%S\")\n",
    ">\n",
    ">print(d)\n",
    ">\n",
    ">print(d.hour)\n",
    ">\n",
    ">print(d.minute)\n",
    ">\n",
    "\n",
    "Output:\n",
    "\n",
    "2017-09-11 18:35:11\n",
    "\n",
    "18\n",
    "\n",
    "35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now for a cool trick. In Python (well, in general), you ultimately define colors with numbers. So, imagine that the number of minutes since midnight (that you just created) corresponds to a color. The function scatter allows you to give this list straight away and plot it (just use the argument c, for example \"c=my_minute_since_midnight_list\")). \n",
    "\n",
    "Do you want to try?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't this explain something?  ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so there seems to be indeed a relationship with time! \n",
    "\n",
    "If this is true, it may be interesting to do a 24-hr average plot. In other words, a plot where the x axis is 0 to 1440 (1440=24 hours X 60 minutes), and you show the average per minute.\n",
    "\n",
    "BTW, it will also be very useful if you add the 5 and 95 quantiles. \n",
    "\n",
    "Do you want to do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, again, you did a lot of stuff. Why not reorganize it again?\n",
    "\n",
    "For example, a new function that receives the file name, and generates all the graphs you did so far.\n",
    "\n",
    "Wouldn't it be cool to just generate those by a single command?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One very important task in Data Science modeling is to find (and understand) correlations between different variables. Let's do a few simple exercises.\n",
    "\n",
    "Let's start with a simple question: are the different areas correlated between them? If yes, it may be interesting knowledge. For example, maybe we can share data between them to predict better, later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.88197083,  0.87922968,  0.63681633],\n",
       "       [ 0.88197083,  1.        ,  0.82631022,  0.66006245],\n",
       "       [ 0.87922968,  0.82631022,  1.        ,  0.67438811],\n",
       "       [ 0.63681633,  0.66006245,  0.67438811,  1.        ]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1,_ =read_csv(\"pickups_zone_1_15min.csv\")\n",
    "s17, _=read_csv(\"pickups_zone_17_15min.csv\")\n",
    "s21, _=read_csv(\"pickups_zone_21_15min.csv\")\n",
    "s28, _=read_csv(\"pickups_zone_28_15min.csv\")\n",
    "\n",
    "np.corrcoef([s1, s17, s21, s28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems all but area 28 are well correlated with each other. Can that show, in the pictures above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, a more interesting question: are there correlations between a given area, and the other areas in earlier time steps? \n",
    "\n",
    "This is a VERY important one. If you find high correlation, for example, between area 1 at time t, with area 17 at time t-1, then you can use area 17 to predict area 1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check this, you need to play a little bit with the vectors. Let's call a vector that is shifted in time for 1 time step, a \"lag1\" vector.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "s1_trimmed=np.array(s1[1:]) #look, it's the SAME vector, except that you start on the second element. Why?\n",
    "s21_lag1=np.array(s21[:-1]) #if this is confusing you now, please ask the teacher to explain. \n",
    "s17_lag1=np.array(s17[:-1])#With a white board near, it will be easy to understand! ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check those correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.89489521,  0.86013243],\n",
       "       [ 0.89489521,  1.        ,  0.82631008],\n",
       "       [ 0.86013243,  0.82631008,  1.        ]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef([s1_trimmed, s17_lag1, s21_lag1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOW! Very interesting!! This means that you can use data from these other areas to predict for area 1... This is useful when there is missing data in area 1, for example... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to replicate this same study, for all different areas. To make it quick, you can define a function that receives the area you want to \"predict for\", and the areas you want to use as \"predictors\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An idea: check the correlation between the series \"s1\" and the series \"s1_lag1\". This is called the autocorrelation of lag 1 of the time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, do this with lag=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the last couple of tasks for today: \n",
    "\n",
    "Create a list, let's call it \"auto_s1\", with the autocorrelations with all lags until 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make a plot such that The x axis is the range(1,120), and y axis is the auto_s1 list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting diagram is called an autocorrelogram! :-) What do you think? Can you explain what's happening in those bumps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
